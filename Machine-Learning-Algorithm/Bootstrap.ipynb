{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 부트스트랩 (Boot strap)\n",
    "*작성일자 : 2020-03-27*\n",
    "\n",
    "부트스트랩 방식은 샘플링 분포를 추정하기 위한 샘플링 기법입니다. <br>\n",
    "부트스트랩 방식의 아이디어는 원본 데이터셋에서 **중복을 허용하여** 샘플링을 반복함으로써<br>\n",
    "모집단으로부터 새로운 데이터를 생성하는 방법입니다.\n",
    "\n",
    "<img src=\"./pic/Bootstrap.PNG\" >\n",
    "\n",
    "### **[ 통계학에서의 부트스트랩 (Bootstrap in statistics) ]**\n",
    "일단 “bootstrapping”이란 용어는 통계학에서 사용된다.<br>\n",
    "이는 가설 검증(test)을 하거나 메트릭(metric)을 계산하기 전에 random sampling을 적용하는 방법을 일컫는다.<br>\n",
    "(이 때에 random samling은 중복을 허용해야 한다.) <br>\n",
    "예를 들자면, 어떤 집단에서 값을 측정했을 때, 그 중에서 임의로 100개를 뽑아서 평균(sample mean)을 구하는 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[ 부트스트랩의 용도 ]**\n",
    "1. 주어진 분포를 알 수 없을 때\n",
    "2. 추가적인 샘플을 구할 수 없을 때 추정량의 통계적 속성을 결정하기 위해서 사용된다.\n",
    "\n",
    "> 하나의 단일 통계치를 얻고자 하면, 전체의 평균을 구하면 되지만 **평균의 신뢰구간**을 구하고자 할 때 <br>\n",
    "* 확률변수의 정확한 분포를 모르는 경우 부트스트랩(bootstrap)을 사용.\n",
    "* 측정된 n개의 데이터 중에서 중복을 허용하여 m개를 뽑고, 그들의 평균을 구하기를 여러 번 반복한다.<br>\n",
    "그럼 평균의 분포를 구할 수 있게 되고, 이로부터 95% 확률로 sample mean이 (a, b) 사이의 구간에 위치한다든가 하는 것을 언급할 수 있다.\n",
    "\n",
    "### **[ ML에서의 부트스트랩 ]**\n",
    "#### 1) 랜덤 샘플링을 통해 training data를 늘릴 때\n",
    "\n",
    "> * 데이터 셋(training set) 내의 데이터 분포가 고르지 않은 경우.\n",
    "    * ex) 사과와 오렌지를 구분하는 classifier를 트레이닝한다고 하자. 만약 training set에 사과 이미지 1만장과 오렌지 이미지 100장이 포함되어 있다면, 항상 사과만 찍는 멍청한 classifier도 99%의 트레이닝 정확도를 보일 것이다. <br>\n",
    "<br>\n",
    "* 이렇게 균형이 맞지 않은 상황에서는 데이터가 적은 클래스의 error는 무시되는 방향으로 트레이닝되기 쉽다.\n",
    "    * 이를 해결하기 위한 방법:\n",
    "        * 첫 번째는 weight를 줄 수 있는 알고리즘을 사용하는 것이고,\n",
    "        * 두 번째는 **“bootstrapping”**을 이용해서 오렌지의 데이터 수를 늘리는 것이며,\n",
    "        * 마지막은 사과 데이터의 수를 역으로 줄이는 것이다.\n",
    "        \n",
    "#### 2) “bootstrapping”을 이용하면 주어진 데이터가 충분하지 않아도 model ensemble을 만들 수 있다.\n",
    "> 똑같은 알고리즘을 통해 m 번 학습시킨다고 하자.<br>\n",
    "이 때 매번 training data를 random sampling하면, 서로 다른 m개의 모델이 만들어진다.<br>\n",
    "각각의 모델은 학습 과정에서 사용된 데이터에 over-fitting 되어 있겠지만, <br>\n",
    "m개 전체를 사용하여 결정을 내리면 over-fitting 걱정이 크게 줄어들 것이다.\n",
    "\n",
    "\n",
    "#### 3) 단일 모델의 성능을 높이기 위한 학습 방법으로도 사용\n",
    "> 모델을 정확도를 높이기 위해서는 같은 데이터를 반복해서 학습시키는 것이 필요한데,<br>\n",
    "단순히 전체 데이터 셋을 트레이닝하는 것은 시간이 오래 걸리고 비효율적이다. <br>\n",
    "충분히 구분히 잘 되는 샘플을 쓸데없이 여러번 학습시키는 데에 많은 시간이 소요되기 때문이다.<br>\n",
    "이럴 때, “bootstrapping”을 이용하여 각 iteration에 사용되는 학습 데이터의 갯수를 줄이고, 어려운 샘플에 큰 비중을 둬서 학습하도록 조절할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suhyun3",
   "language": "python",
   "name": "suhyun3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
